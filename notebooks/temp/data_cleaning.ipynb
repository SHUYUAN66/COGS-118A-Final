{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ADULT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,  OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def incomeFixer(x):\n",
    "    if x == \"<=50K\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def clean_adult(df):\n",
    "    ad_var = ['age','workclass','fnlwgt','education',\n",
    "    'education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','target']\n",
    "    df.columns = ad_var\n",
    "    copy=df.copy()\n",
    "    copy = copy.replace({' ?': np.nan, 0: np.nan, 99999: np.nan})\n",
    "    copy = copy.replace(\" \",\"\",regex=True)\n",
    "    copy = copy.replace(\"-\",\"\",regex=True)\n",
    "    # f.replace('_', '', regex=True)\n",
    "    copy[\"target\"] = copy.apply(lambda x: incomeFixer(x['target']), axis=1) \n",
    "    cp_dp = copy.copy()\n",
    "    cp_dp = cp_dp.drop(columns=['education','fnlwgt','capital-gain','capital-loss'])\n",
    "    DataFrame = cp_dp.copy()\n",
    "    categorical_missing = ['workclass','occupation','native-country']\n",
    "    for ColName in categorical_missing:\n",
    "        most_frequent_category=DataFrame[ColName].mode()[0]\n",
    "    # replace nan values with most occured category\n",
    "        DataFrame[ColName + \"_Imputed\"] = DataFrame[ColName]\n",
    "        DataFrame[ColName + \"_Imputed\"].fillna(most_frequent_category,inplace=True)\n",
    "        DataFrame[ColName] = DataFrame[ColName + \"_Imputed\"]\n",
    "        DataFrame = DataFrame.drop([ColName + \"_Imputed\"], axis = 1)\n",
    "    return DataFrame\n",
    "\n",
    "\n",
    "def random_adult():\n",
    "    adult_raw = pd.read_csv('../data/raw/adult/adult.data', header=None)\n",
    "    cleaning_adult = clean_adult(adult_raw)\n",
    "    adult_train = cleaning_adult.sample(n=5000, replace=False)\n",
    "    adult_test = cleaning_adult.drop(adult_train.index)\n",
    "    adult_train.to_csv('../data/train/adult.csv', index=False)\n",
    "    adult_test .to_csv('../data/test/adult.csv', index=False)\n",
    "    adult_train=pd.read_csv('../data/train/adult.csv')\n",
    "    adlt_test=pd.read_csv('../data/train/adult.csv')\n",
    "    return [adult_train, adult_test]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/anthea-mac/Documents/FA20/COGS118A/Final Project/notebooks/temp\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/anthea-mac/Documents/FA20/COGS118A/Final Project/notebooks/temp\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './test/adult.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8b18941c67ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pwd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test/adult.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './test/adult.csv'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'data/')\n",
    "!pwd\n",
    "pd.read_csv('./test/adult.csv').head()"
   ]
  },
  {
   "source": [
    "# NURSERY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting JSON encoded data into Python dictionary\nDecoded JSON Data From File\nparents : ['usual', 'pretentious', 'greatpret']\nhas_nurs : ['verycrit', 'critical', 'improper', 'lessproper', 'proper']\nform : ['foster', 'incomplete', 'complete', 'completed']\nchildren : ['1', '2', '3', 'more']\nhousing : ['critical', 'lessconv', 'convenient']\nsocial : ['problematic', 'slightlyprob', 'nonprob']\nhealth : ['notrecom', 'priority', 'recommended']\ntarget : ['notrecom', 'priority', 'specprior', 'recommend', 'veryrecom']\nDone reading json file\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  parents has_nurs      form children     housing        social       health  \\\n0   usual   proper  complete        1  convenient       nonprob  recommended   \n1   usual   proper  complete        1  convenient       nonprob     priority   \n2   usual   proper  complete        1  convenient       nonprob     notrecom   \n3   usual   proper  complete        1  convenient  slightlyprob  recommended   \n4   usual   proper  complete        1  convenient  slightlyprob     priority   \n\n   target  finance  \n0       0        1  \n1       3        1  \n2       0        1  \n3       0        1  \n4       3        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parents</th>\n      <th>has_nurs</th>\n      <th>form</th>\n      <th>children</th>\n      <th>housing</th>\n      <th>social</th>\n      <th>health</th>\n      <th>target</th>\n      <th>finance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>nonprob</td>\n      <td>recommended</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>nonprob</td>\n      <td>priority</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>nonprob</td>\n      <td>notrecom</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>slightlyprob</td>\n      <td>recommended</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>slightlyprob</td>\n      <td>priority</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import json\n",
    "with open(\"nsrorder.json\", \"r\") as read_file:\n",
    "    print(\"Converting JSON encoded data into Python dictionary\")\n",
    "    developer = json.load(read_file)\n",
    "    print(\"Decoded JSON Data From File\")\n",
    "    for key, value in developer.items():\n",
    "        print(key, \":\", value)\n",
    "    print(\"Done reading json file\")\n",
    "def check_item(raw, in_r):\n",
    "    for i in in_r:\n",
    "        if i in raw:\n",
    "            pass\n",
    "        else:\n",
    "            print('wrong item is : ', i)\n",
    "    #return'No Error Found in column ' \n",
    "def clean_nsr(df):\n",
    "    od =developer\n",
    "    nsr_var = ['parents', 'has_nurs', 'form', 'children', 'housing','finance','social', 'health','target']\n",
    "    df.columns = nsr_var\n",
    "    raw = df.copy()\n",
    "    raw = raw.replace({'inconv':0, 'convenient':1})\n",
    "    df = df.replace('_', '', regex=True)\n",
    "    df = df.drop(columns = ['finance'])\n",
    "    for i in df.columns:\n",
    "        df[i] = df[i].astype('category')\n",
    "        r = od[i]\n",
    "        cat_r = CategoricalDtype(categories=r, ordered=True)\n",
    "        # give the order\n",
    "        df[i] = df[i].cat.reorder_categories(r, ordered=True)\n",
    "\n",
    "    df['finance'] = raw['finance']\n",
    "    return df\n",
    "nsr_raw = pd.read_csv('../data/raw/nursey/nursery.data', header=None)\n",
    "cleaning_nsr = clean_nsr(nsr_raw)\n",
    "cleaning_nsr['target'] =cleaning_nsr['target'].replace( ['notrecom', 'recommend', 'veryrecom','priority', 'specprior'],[0,0,2,3,4] )\n",
    "display(cleaning_nsr.head())\n",
    "nsr_train = cleaning_nsr.sample(n=10000, replace=False)\n",
    "nsr_test = cleaning_nsr.drop(nsr_train.index)\n",
    "nsr_train.to_csv('../data/train/nsr.csv', index=False)\n",
    "nsr_test .to_csv('../data/test/nsr.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  parents has_nurs      form children     housing        social       health  \\\n",
       "0   usual   proper  complete        1  convenient  slightlyprob  recommended   \n",
       "1   usual   proper  complete        1  convenient  slightlyprob     notrecom   \n",
       "2   usual   proper  complete        1  convenient   problematic     priority   \n",
       "3   usual   proper  complete        1  convenient   problematic     notrecom   \n",
       "4   usual   proper  complete        1  convenient       nonprob     priority   \n",
       "\n",
       "   finance  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parents</th>\n      <th>has_nurs</th>\n      <th>form</th>\n      <th>children</th>\n      <th>housing</th>\n      <th>social</th>\n      <th>health</th>\n      <th>finance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>slightlyprob</td>\n      <td>recommended</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>slightlyprob</td>\n      <td>notrecom</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>problematic</td>\n      <td>priority</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>problematic</td>\n      <td>notrecom</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>nonprob</td>\n      <td>priority</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df = pd.read_csv('../data/test/nsr.csv')\n",
    "y = df.target\n",
    "X=df.drop(columns=['target'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    2960.000000\n",
       "mean        2.299324\n",
       "std         1.676105\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         3.000000\n",
       "75%         4.000000\n",
       "max         4.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_ordinal = ColumnTransformer(transformers=[('categoricals', OrdinalEncoder(),\n",
    "                                                selector(dtype_include=[\"object\", \"category\"])),\n",
    "                                               ('numericals', StandardScaler(), selector(\n",
    "                                                   dtype_include=[\"int\", 'float']))\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  parents has_nurs      form children     housing        social       health  \\\n",
       "0   usual   proper  complete        1  convenient       nonprob     notrecom   \n",
       "1   usual   proper  complete        1  convenient  slightlyprob  recommended   \n",
       "2   usual   proper  complete        1  convenient  slightlyprob     priority   \n",
       "3   usual   proper  complete        1  convenient  slightlyprob     notrecom   \n",
       "4   usual   proper  complete        1  convenient   problematic  recommended   \n",
       "\n",
       "   target  finance  \n",
       "0       0        1  \n",
       "1       1        1  \n",
       "2       3        1  \n",
       "3       0        1  \n",
       "4       3        1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parents</th>\n      <th>has_nurs</th>\n      <th>form</th>\n      <th>children</th>\n      <th>housing</th>\n      <th>social</th>\n      <th>health</th>\n      <th>target</th>\n      <th>finance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>nonprob</td>\n      <td>notrecom</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>slightlyprob</td>\n      <td>recommended</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>slightlyprob</td>\n      <td>priority</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>slightlyprob</td>\n      <td>notrecom</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>problematic</td>\n      <td>recommended</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "# AVL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10430 entries, 0 to 10429\nData columns (total 11 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   0       10430 non-null  float64\n 1   1       10430 non-null  float64\n 2   2       10430 non-null  float64\n 3   3       10430 non-null  float64\n 4   4       10430 non-null  float64\n 5   5       10430 non-null  float64\n 6   6       10430 non-null  float64\n 7   7       10430 non-null  float64\n 8   8       10430 non-null  float64\n 9   9       10430 non-null  float64\n 10  target  10430 non-null  object \ndtypes: float64(10), object(1)\nmemory usage: 896.5+ KB\nNone\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.266074 -0.165620  0.320980  0.483299  0.172340  0.273364  0.371178   \n",
       "1  0.130292  0.870736 -3.210528  0.062493  0.261718  1.436060  1.465940   \n",
       "2 -0.116585  0.069915  0.068476 -0.783147  0.261718  0.439463 -0.081827   \n",
       "3  0.031541  0.297600 -3.210528 -0.583590 -0.721442 -0.307984  0.710932   \n",
       "4  0.229043  0.807926 -0.052442  0.082634  0.261718  0.148790  0.635431   \n",
       "\n",
       "          7         8         9 target  \n",
       "0  0.929823  0.251173  0.159345      A  \n",
       "1  0.636203  0.282354  0.515587      A  \n",
       "2 -0.888236 -0.123005  0.582939      A  \n",
       "3  1.051693  0.594169 -0.533994      A  \n",
       "4  0.051062  0.032902 -0.086652      F  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.266074</td>\n      <td>-0.165620</td>\n      <td>0.320980</td>\n      <td>0.483299</td>\n      <td>0.172340</td>\n      <td>0.273364</td>\n      <td>0.371178</td>\n      <td>0.929823</td>\n      <td>0.251173</td>\n      <td>0.159345</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.130292</td>\n      <td>0.870736</td>\n      <td>-3.210528</td>\n      <td>0.062493</td>\n      <td>0.261718</td>\n      <td>1.436060</td>\n      <td>1.465940</td>\n      <td>0.636203</td>\n      <td>0.282354</td>\n      <td>0.515587</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.116585</td>\n      <td>0.069915</td>\n      <td>0.068476</td>\n      <td>-0.783147</td>\n      <td>0.261718</td>\n      <td>0.439463</td>\n      <td>-0.081827</td>\n      <td>-0.888236</td>\n      <td>-0.123005</td>\n      <td>0.582939</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.031541</td>\n      <td>0.297600</td>\n      <td>-3.210528</td>\n      <td>-0.583590</td>\n      <td>-0.721442</td>\n      <td>-0.307984</td>\n      <td>0.710932</td>\n      <td>1.051693</td>\n      <td>0.594169</td>\n      <td>-0.533994</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.229043</td>\n      <td>0.807926</td>\n      <td>-0.052442</td>\n      <td>0.082634</td>\n      <td>0.261718</td>\n      <td>0.148790</td>\n      <td>0.635431</td>\n      <td>0.051062</td>\n      <td>0.032902</td>\n      <td>-0.086652</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "\n",
    "avl=pd.read_csv('../data/raw/avl_set/avila-tr.txt', header=None)\n",
    "avl.columns = avl.columns.astype(str)\n",
    "avl=avl.rename(columns={'10':'target'})\n",
    "avl_train = avl.sample(n=5000, replace=False)\n",
    "avl_test = cleaning_nsr.drop(avl_train.index)\n",
    "nsr_train.to_csv('../data/train/avl.csv', index=False)\n",
    "nsr_test .to_csv('../data/test/avl.csv', index=False)\n",
    "print(avl.info())\n",
    "avl.head()\n"
   ]
  },
  {
   "source": [
    "# POWER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "prediction = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': 4, '2': 2, '3': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dic={}\n",
    "dic['1']=4\n",
    "dic['2'] =2\n",
    "dic['3']=1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_values([4, 2, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "dic.keys()\n",
    "dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "list(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}