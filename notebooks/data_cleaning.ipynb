{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ADULT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,  OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def incomeFixer(x):\n",
    "    if x == \" <=50K\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def clean_adult(df):\n",
    "    ad_var = ['age','workclass','fnlwgt','education',\n",
    "    'education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','target']\n",
    "    df.columns = ad_var\n",
    "    copy=df.copy()\n",
    "    copy = copy.replace({' ?': np.nan, 0: np.nan, 99999: np.nan})\n",
    "    copy[\"target\"] = copy.apply(lambda x: incomeFixer(x['target']), axis=1) \n",
    "    cp_dp = copy.copy()\n",
    "    cp_dp = cp_dp.drop(columns=['education','fnlwgt','capital-gain','capital-loss'])\n",
    "    DataFrame = cp_dp.copy()\n",
    "    categorical_missing = ['workclass','occupation','native-country']\n",
    "    for ColName in categorical_missing:\n",
    "        most_frequent_category=DataFrame[ColName].mode()[0]\n",
    "    # replace nan values with most occured category\n",
    "        DataFrame[ColName + \"_Imputed\"] = DataFrame[ColName]\n",
    "        DataFrame[ColName + \"_Imputed\"].fillna(most_frequent_category,inplace=True)\n",
    "        DataFrame[ColName] = DataFrame[ColName + \"_Imputed\"]\n",
    "        DataFrame = DataFrame.drop([ColName + \"_Imputed\"], axis = 1)\n",
    "    return DataFrame\n",
    "\n",
    "\n",
    "\n",
    "adult_raw = pd.read_csv('../data/raw/adult/adult.data', header=None)\n",
    "cleaning_adult = clean_adult(adult_raw)\n",
    "adult_train = cleaning_adult.sample(n=5000, replace=False)\n",
    "adult_test = cleaning_adult.drop(adult_train.index)\n",
    "adult_train.to_csv('../data/train/adult.csv', index=False)\n",
    "adult_test .to_csv('../data/test/adult.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# NURSERY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "parents ['usual' 'pretentious' 'great_pret']\nhas_nurs ['proper' 'less_proper' 'improper' 'critical' 'very_crit']\nform ['complete' 'completed' 'incomplete' 'foster']\nchildren ['1' '2' '3' 'more']\nhousing ['convenient' 'less_conv' 'critical']\nfinance ['convenient' 'inconv']\nsocial ['nonprob' 'slightly_prob' 'problematic']\nhealth ['recommended' 'priority' 'not_recom']\ntarget ['recommend' 'priority' 'not_recom' 'very_recom' 'spec_prior']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def check_item(raw, in_r):\n",
    "    for i in in_r:\n",
    "        if i in raw:\n",
    "            pass\n",
    "        else:\n",
    "            print('wrong item is : ', i)\n",
    "    #return'No Error Found in column ' \n",
    "def clean_nsr(df):\n",
    "    od={}\n",
    "    nsr_var = ['parents', 'has_nurs', 'form', 'children', 'housing','finance','social', 'health','target']\n",
    "    df.columns = nsr_var\n",
    "    for col in df:\n",
    "        od[col] = df [col].unique()\n",
    "        print(col , od[col])\n",
    "    #print(od)\n",
    "    raw = df.copy()\n",
    "    raw = raw.replace({'inconv':0, 'convenient':1})\n",
    "    df = df.drop(columns = ['finance'])\n",
    "    #display(df.head())\n",
    "    for i in df.columns:\n",
    "    # make sure that columns are categorical type\n",
    "        df[i] = df[i].astype('category')\n",
    "    # obtain oder first\n",
    "        r = od[i]\n",
    "        #print(check_item(df[i].unique(), r)+ i)\n",
    "        cat_r = CategoricalDtype(categories=r, ordered=True)\n",
    "        # give the order\n",
    "        df[i] = df[i].cat.reorder_categories(r, ordered=True)\n",
    "\n",
    "    df['finance'] = raw['finance']\n",
    "    return df\n",
    "nsr_raw = pd.read_csv('../data/raw/nursey/nursery.data', header=None)\n",
    "cleaning_nsr = clean_nsr(nsr_raw)\n",
    "nsr_train = cleaning_nsr.sample(n=5000, replace=False)\n",
    "nsr_test = cleaning_nsr.drop(nsr_train.index)\n",
    "nsr_train.to_csv('../data/train/nsr.csv', index=False)\n",
    "nsr_test .to_csv('../data/test/nsr.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/test/nsr.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_ordinal = ColumnTransformer(transformers=[('categoricals', OrdinalEncoder(),\n",
    "                                                selector(dtype_include=[\"object\", \"category\"])),\n",
    "                                               ('numericals', StandardScaler(), selector(\n",
    "                                                   dtype_include=[\"int\", 'float']))\n",
    "                                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fit_transform() missing 1 required positional argument: 'X'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-bb3327cb51ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mColumnTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit_transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "cp = np.array(ColumnTransformer.fit_transform(df), dtype = np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('categoricals', OrdinalEncoder(),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7fc6b0376340>),\n",
       "                                ('numericals', StandardScaler(),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7fc6b0376610>)])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "# AVL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10430 entries, 0 to 10429\nData columns (total 11 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   0       10430 non-null  float64\n 1   1       10430 non-null  float64\n 2   2       10430 non-null  float64\n 3   3       10430 non-null  float64\n 4   4       10430 non-null  float64\n 5   5       10430 non-null  float64\n 6   6       10430 non-null  float64\n 7   7       10430 non-null  float64\n 8   8       10430 non-null  float64\n 9   9       10430 non-null  float64\n 10  target  10430 non-null  object \ndtypes: float64(10), object(1)\nmemory usage: 896.5+ KB\nNone\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.266074 -0.165620  0.320980  0.483299  0.172340  0.273364  0.371178   \n",
       "1  0.130292  0.870736 -3.210528  0.062493  0.261718  1.436060  1.465940   \n",
       "2 -0.116585  0.069915  0.068476 -0.783147  0.261718  0.439463 -0.081827   \n",
       "3  0.031541  0.297600 -3.210528 -0.583590 -0.721442 -0.307984  0.710932   \n",
       "4  0.229043  0.807926 -0.052442  0.082634  0.261718  0.148790  0.635431   \n",
       "\n",
       "          7         8         9 target  \n",
       "0  0.929823  0.251173  0.159345      A  \n",
       "1  0.636203  0.282354  0.515587      A  \n",
       "2 -0.888236 -0.123005  0.582939      A  \n",
       "3  1.051693  0.594169 -0.533994      A  \n",
       "4  0.051062  0.032902 -0.086652      F  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.266074</td>\n      <td>-0.165620</td>\n      <td>0.320980</td>\n      <td>0.483299</td>\n      <td>0.172340</td>\n      <td>0.273364</td>\n      <td>0.371178</td>\n      <td>0.929823</td>\n      <td>0.251173</td>\n      <td>0.159345</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.130292</td>\n      <td>0.870736</td>\n      <td>-3.210528</td>\n      <td>0.062493</td>\n      <td>0.261718</td>\n      <td>1.436060</td>\n      <td>1.465940</td>\n      <td>0.636203</td>\n      <td>0.282354</td>\n      <td>0.515587</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.116585</td>\n      <td>0.069915</td>\n      <td>0.068476</td>\n      <td>-0.783147</td>\n      <td>0.261718</td>\n      <td>0.439463</td>\n      <td>-0.081827</td>\n      <td>-0.888236</td>\n      <td>-0.123005</td>\n      <td>0.582939</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.031541</td>\n      <td>0.297600</td>\n      <td>-3.210528</td>\n      <td>-0.583590</td>\n      <td>-0.721442</td>\n      <td>-0.307984</td>\n      <td>0.710932</td>\n      <td>1.051693</td>\n      <td>0.594169</td>\n      <td>-0.533994</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.229043</td>\n      <td>0.807926</td>\n      <td>-0.052442</td>\n      <td>0.082634</td>\n      <td>0.261718</td>\n      <td>0.148790</td>\n      <td>0.635431</td>\n      <td>0.051062</td>\n      <td>0.032902</td>\n      <td>-0.086652</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "\n",
    "avl=pd.read_csv('../data/raw/avl_set/avila-tr.txt', header=None)\n",
    "avl.columns = avl.columns.astype(str)\n",
    "avl=avl.rename(columns={'10':'target'})\n",
    "avl_train = avl.sample(n=5000, replace=False)\n",
    "avl_test = cleaning_nsr.drop(avl_train.index)\n",
    "nsr_train.to_csv('../data/train/avl.csv', index=False)\n",
    "nsr_test .to_csv('../data/test/avl.csv', index=False)\n",
    "print(avl.info())\n",
    "avl.head()\n"
   ]
  },
  {
   "source": [
    "# POWER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AutoML directory: AutoML_1\n",
      "The task is multiclass_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Decision Tree', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'all_ints_encoding', 'loo_encoding', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree logloss 0.4222 trained in 1.29 seconds\n",
      "Adjust validation. Remove: AutoML_1/1_DecisionTree\n",
      "Validation strategy: 10-fold CV Shuffle,Stratify\n",
      "* Step simple_algorithms will try to check up to 2 models\n",
      "1_DecisionTree logloss 0.449552 trained in 13.4 seconds\n",
      "2_DecisionTree logloss 0.368499 trained in 8.96 seconds\n",
      "* Step default_algorithms will try to check up to 7 models\n",
      "2020-12-18 04:21:29,402 supervised.exceptions ERROR Stop training after the first fold. Time needed to train on the first fold 674.0 seconds. The time estimate for training on all folds is larger than total_time_limit.\n",
      "There was an error during 3_Default_Xgboost training.\n",
      "Please check AutoML_1/errors.md for details.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-9dca37318556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0mauto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Compete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mAutoML\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReturns\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/base_automl.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    898\u001b[0m                             )\n\u001b[1;32m    899\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                             \u001b[0mtrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"trained\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"skipped\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"final_loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_final_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/base_automl.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;34mf\"Train model #{len(self._models)+1} / Model name: {params['name']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         )\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;31m# save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/model_framework.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_iteration_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                     learner.fit(\n\u001b[0m\u001b[1;32m    152\u001b[0m                         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_to_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/algorithms/lightgbm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_validation, y_validation, log_to_file)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mesr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mevals_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             self.model = lgb.train(\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2368\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2371\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train/avl.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=['target']), df.target, test_size=0.25\n",
    "   \n",
    ")\n",
    "auto = AutoML(mode=\"Compete\")\n",
    "auto.fit(X_train,y_train)\n",
    "predictions = automl.predict_all(X_test)\n",
    "\n",
    "print(predictions.head())\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, predictions[\"label\"].astype(int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "prediction = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': 4, '2': 2, '3': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dic={}\n",
    "dic['1']=4\n",
    "dic['2'] =2\n",
    "dic['3']=1\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_values([4, 2, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "dic.keys()\n",
    "dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "list(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}