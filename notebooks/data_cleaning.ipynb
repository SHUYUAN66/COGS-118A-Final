{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ADULT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def incomeFixer(x):\n",
    "    if x == \" <=50K\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def clean_adult(df):\n",
    "    ad_var = ['age','workclass','fnlwgt','education',\n",
    "    'education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','target']\n",
    "    df.columns = ad_var\n",
    "    copy=df.copy()\n",
    "    copy = copy.replace({' ?': np.nan, 0: np.nan, 99999: np.nan})\n",
    "    copy[\"target\"] = copy.apply(lambda x: incomeFixer(x['target']), axis=1) \n",
    "    cp_dp = copy.copy()\n",
    "    cp_dp = cp_dp.drop(columns=['education','fnlwgt','capital-gain','capital-loss'])\n",
    "    DataFrame = cp_dp.copy()\n",
    "    categorical_missing = ['workclass','occupation','native-country']\n",
    "    for ColName in categorical_missing:\n",
    "        most_frequent_category=DataFrame[ColName].mode()[0]\n",
    "    # replace nan values with most occured category\n",
    "        DataFrame[ColName + \"_Imputed\"] = DataFrame[ColName]\n",
    "        DataFrame[ColName + \"_Imputed\"].fillna(most_frequent_category,inplace=True)\n",
    "        DataFrame[ColName] = DataFrame[ColName + \"_Imputed\"]\n",
    "        DataFrame = DataFrame.drop([ColName + \"_Imputed\"], axis = 1)\n",
    "    return DataFrame\n",
    "\n",
    "\n",
    "\n",
    "adult_raw = pd.read_csv('../data/raw/adult/adult.data', header=None)\n",
    "cleaning_adult = clean_adult(adult_raw)\n",
    "adult_train = cleaning_adult.sample(n=5000, replace=False)\n",
    "adult_test = cleaning_adult.drop(adult_train.index)\n",
    "adult_train.to_csv('../data/train/adult.csv', index=False)\n",
    "adult_test .to_csv('../data/test/adult.csv', index=False)"
   ]
  },
  {
   "source": [
    "# NURSERY"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'parents': array(['usual', 'pretentious', 'great_pret'], dtype=object), 'has_nurs': array(['proper', 'less_proper', 'improper', 'critical', 'very_crit'],\n      dtype=object), 'form': array(['complete', 'completed', 'incomplete', 'foster'], dtype=object), 'children': array(['1', '2', '3', 'more'], dtype=object), 'housing': array(['convenient', 'less_conv', 'critical'], dtype=object), 'finance': array(['convenient', 'inconv'], dtype=object), 'social': array(['nonprob', 'slightly_prob', 'problematic'], dtype=object), 'health': array(['recommended', 'priority', 'not_recom'], dtype=object), 'target': array(['recommend', 'priority', 'not_recom', 'very_recom', 'spec_prior'],\n      dtype=object)}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  parents has_nurs      form children     housing         social       health  \\\n0   usual   proper  complete        1  convenient        nonprob  recommended   \n1   usual   proper  complete        1  convenient        nonprob     priority   \n2   usual   proper  complete        1  convenient        nonprob    not_recom   \n3   usual   proper  complete        1  convenient  slightly_prob  recommended   \n4   usual   proper  complete        1  convenient  slightly_prob     priority   \n\n      target  \n0  recommend  \n1   priority  \n2  not_recom  \n3  recommend  \n4   priority  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parents</th>\n      <th>has_nurs</th>\n      <th>form</th>\n      <th>children</th>\n      <th>housing</th>\n      <th>social</th>\n      <th>health</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>nonprob</td>\n      <td>recommended</td>\n      <td>recommend</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>nonprob</td>\n      <td>priority</td>\n      <td>priority</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>nonprob</td>\n      <td>not_recom</td>\n      <td>not_recom</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>slightly_prob</td>\n      <td>recommended</td>\n      <td>recommend</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>usual</td>\n      <td>proper</td>\n      <td>complete</td>\n      <td>1</td>\n      <td>convenient</td>\n      <td>slightly_prob</td>\n      <td>priority</td>\n      <td>priority</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "parents\nNo Error Found in column parents\nhas_nurs\nNo Error Found in column has_nurs\nform\nNo Error Found in column form\nchildren\nNo Error Found in column children\nhousing\nNo Error Found in column housing\nsocial\nNo Error Found in column social\nhealth\nNo Error Found in column health\ntarget\nNo Error Found in column target\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def check_item(raw, in_r):\n",
    "    for i in in_r:\n",
    "        if i in raw:\n",
    "            pass\n",
    "        else:\n",
    "            print('wrong item is : ', i)\n",
    "    return'No Error Found in column ' \n",
    "def clean_nsr(df):\n",
    "    od={}\n",
    "    nsr_var = ['parents', 'has_nurs', 'form', 'children', 'housing','finance','social', 'health','target']\n",
    "    df.columns = nsr_var\n",
    "    for col in df:\n",
    "        od[col] = df [col].unique()\n",
    "    print(od)\n",
    "    raw = df.copy()\n",
    "    raw = raw.replace({'inconv':0, 'convenient':1})\n",
    "    df = df.drop(columns = ['finance'])\n",
    "    display(df.head())\n",
    "    for i in df.columns:\n",
    "    # make sure that columns are categorical type\n",
    "        print(i)\n",
    "        df[i] = df[i].astype('category')\n",
    "    # obtain oder first\n",
    "        r = od[i]\n",
    "        print(check_item(df[i].unique(), r)+ i)\n",
    "        cat_r = CategoricalDtype(categories=r, ordered=True)\n",
    "        # give the order\n",
    "        df[i] = df[i].cat.reorder_categories(r, ordered=True)\n",
    "\n",
    "    df['finance'] = raw['finance']\n",
    "    return df\n",
    "nsr_raw = pd.read_csv('../data/raw/nursey/nursery.data', header=None)\n",
    "cleaning_nsr = clean_nsr(nsr_raw)\n",
    "nsr_train = cleaning_nsr.sample(n=5000, replace=False)\n",
    "nsr_test = cleaning_nsr.drop(nsr_train.index)\n",
    "nsr_train.to_csv('../data/train/nsr.csv', index=False)\n",
    "nsr_test .to_csv('../data/test/nsr.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'parents': ['usual', 'pretentious', 'great_pret'], 'has_nurs': ['very_crit', 'critical', 'improper', 'less_proper', 'proper'], 'form': ['foster', 'incomplete', 'complete', 'completed'], 'children': ['1', '2', '3', 'more'], 'housing': ['critical', 'less_conv', 'convenient'], 'social': ['problematic', 'slightly_prob', 'nonprob'], 'health': ['not_recom', 'priority', 'recommended'], 'target': ['not_recom', 'priority', 'spec_prior', 'very_recom']}\nNo Error Found in column parents\nNo Error Found in column has_nurs\nNo Error Found in column form\nNo Error Found in column children\nNo Error Found in column housing\nNo Error Found in column social\nNo Error Found in column health\nNo Error Found in column target\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 9 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   parents   5000 non-null   category\n 1   has_nurs  5000 non-null   category\n 2   form      5000 non-null   category\n 3   children  5000 non-null   category\n 4   housing   5000 non-null   category\n 5   social    5000 non-null   category\n 6   health    5000 non-null   category\n 7   target    5000 non-null   category\n 8   finance   5000 non-null   int64   \ndtypes: category(8), int64(1)\nmemory usage: 79.4 KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "column_name : parents  =>  ['pretentious' 'great_pret' 'usual']\n In (a<b<c) order,\n   design the order to be:  ['usual', 'pretentious', 'great_pret']  \n\n\ncolumn_name : has_nurs  =>  ['very_crit' 'critical' 'proper' 'improper' 'less_proper']\n In (a<b<c) order,\n   design the order to be:  ['very_crit', 'critical', 'improper', 'less_proper', 'proper']  \n\n\ncolumn_name : form  =>  ['complete' 'completed' 'foster' 'incomplete']\n In (a<b<c) order,\n   design the order to be:  ['foster', 'incomplete', 'complete', 'completed']  \n\n\ncolumn_name : children  =>  ['3' '1' 'more' '2']\n In (a<b<c) order,\n   design the order to be:  ['1', '2', '3', 'more']  \n\n\ncolumn_name : housing  =>  ['critical' 'less_conv' 'convenient']\n In (a<b<c) order,\n   design the order to be:  ['critical', 'less_conv', 'convenient']  \n\n\n[finance] is column only has binary labels \n\ncolumn_name : social  =>  ['slightly_prob' 'nonprob' 'problematic']\n In (a<b<c) order,\n   design the order to be:  ['problematic', 'slightly_prob', 'nonprob']  \n\n\ncolumn_name : health  =>  ['not_recom' 'recommended' 'priority']\n In (a<b<c) order,\n   design the order to be:  ['not_recom', 'priority', 'recommended']  \n\n\ncolumn_name : target  =>  ['not_recom' 'priority' 'spec_prior' 'very_recom']\n In (a<b<c) order,\n   design the order to be:  ['not_recom', 'priority', 'spec_prior', 'very_recom']  \n\n\nNo Error Found in column parents\nNo Error Found in column has_nurs\nNo Error Found in column form\nNo Error Found in column children\nNo Error Found in column housing\nNo Error Found in column social\nNo Error Found in column health\nNo Error Found in column target\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 9 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   parents   5000 non-null   category\n 1   has_nurs  5000 non-null   category\n 2   form      5000 non-null   category\n 3   children  5000 non-null   category\n 4   housing   5000 non-null   category\n 5   social    5000 non-null   category\n 6   health    5000 non-null   category\n 7   target    5000 non-null   category\n 8   finance   5000 non-null   int64   \ndtypes: category(8), int64(1)\nmemory usage: 79.4 KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Column_Name  Num_Unique\n",
       "5     finance           2\n",
       "0     parents           3\n",
       "4     housing           3\n",
       "6      social           3\n",
       "7      health           3\n",
       "2        form           4\n",
       "3    children           4\n",
       "8      target           4\n",
       "1    has_nurs           5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column_Name</th>\n      <th>Num_Unique</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>finance</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>parents</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>housing</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>social</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>health</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>form</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>children</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>target</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>has_nurs</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "unique_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "parents ['pretentious', 'usual', 'great_pret']\nCategories (3, object): ['usual' < 'pretentious' < 'great_pret']  \n\nhas_nurs ['improper', 'very_crit', 'critical', 'proper', 'less_proper']\nCategories (5, object): ['very_crit' < 'critical' < 'improper' < 'less_proper' < 'proper']  \n\nform ['complete', 'incomplete', 'completed', 'foster']\nCategories (4, object): ['foster' < 'incomplete' < 'complete' < 'completed']  \n\nchildren ['2', '3', 'more', '1']\nCategories (4, object): ['2', '3', 'more', '1']  \n\nhousing ['critical', 'less_conv', 'convenient']\nCategories (3, object): ['critical', 'less_conv', 'convenient']  \n\nfinance ['convenient', 'inconv']\nCategories (2, object): ['convenient', 'inconv']  \n\nsocial ['slightly_prob', 'nonprob', 'problematic']\nCategories (3, object): ['slightly_prob', 'nonprob', 'problematic']  \n\nhealth ['priority', 'recommended', 'not_recom']\nCategories (3, object): ['priority', 'recommended', 'not_recom']  \n\ntarget ['spec_prior', 'not_recom', 'priority', 'very_recom']\nCategories (4, object): ['spec_prior', 'not_recom', 'priority', 'very_recom']  \n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 5000 entries, 6142 to 10841\nData columns (total 9 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   parents   5000 non-null   category\n 1   has_nurs  5000 non-null   category\n 2   form      5000 non-null   category\n 3   children  5000 non-null   category\n 4   housing   5000 non-null   category\n 5   finance   5000 non-null   category\n 6   social    5000 non-null   category\n 7   health    5000 non-null   category\n 8   target    5000 non-null   category\ndtypes: category(9)\nmemory usage: 84.3 KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6142     pretentious\n4041           usual\n12506     great_pret\n8147     pretentious\n7844     pretentious\n            ...     \n11195     great_pret\n26             usual\n12846     great_pret\n655            usual\n10841     great_pret\nName: parents, Length: 5000, dtype: category\nCategories (3, object): ['usual' < 'pretentious' < 'great_pret']\n6142      improper\n4041     very_crit\n12506    very_crit\n8147     very_crit\n7844     very_crit\n           ...    \n11195     improper\n26          proper\n12846    very_crit\n655         proper\n10841     improper\nName: has_nurs, Length: 5000, dtype: category\nCategories (5, object): ['very_crit' < 'critical' < 'improper' < 'less_proper' < 'proper']\n6142       complete\n4041     incomplete\n12506     completed\n8147      completed\n7844       complete\n            ...    \n11195        foster\n26         complete\n12846        foster\n655          foster\n10841    incomplete\nName: form, Length: 5000, dtype: category\nCategories (4, object): ['foster' < 'incomplete' < 'complete' < 'completed']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "items in new_categories are not the same as in old categories",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1b5acc4e1aec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcat_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_create_delegator_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delegate_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m_delegate_method\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2590\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2593\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mreorder_categories\u001b[0;34m(self, new_categories, ordered, inplace)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    950\u001b[0m                 \u001b[0;34m\"items in new_categories are not the same as in old categories\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: items in new_categories are not the same as in old categories"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    r = od[i]\n",
    "    cat_r = CategoricalDtype(categories=r, ordered=True)\n",
    "    print(df[i].cat.reorder_categories(r, ordered=True))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].nunique() < 600 and col not in cols_to_exclude:\n",
    "        df[col] = df[col].astype('category')\n",
    "cats_to_order = [\"Non-covered Recipient Entity\", \"Covered Recipient Teaching Hospital\",\n",
    "                 \"Covered Recipient Physician\", \"Non-covered Recipient Individual\"]\n",
    "covered_type = CategoricalDtype(categories=cats_to_order, ordered=True)\n",
    "Then, explicitly re_order the category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           parents   has_nurs        form children     housing     finance  \\\n",
       "6142   pretentious   improper    complete        2    critical  convenient   \n",
       "4041         usual  very_crit  incomplete        3    critical      inconv   \n",
       "12506   great_pret  very_crit   completed     more   less_conv      inconv   \n",
       "8147   pretentious  very_crit   completed        3    critical      inconv   \n",
       "7844   pretentious  very_crit    complete        2  convenient      inconv   \n",
       "\n",
       "              social       health      target  \n",
       "6142   slightly_prob     priority  spec_prior  \n",
       "4041         nonprob  recommended  spec_prior  \n",
       "12506  slightly_prob    not_recom   not_recom  \n",
       "8147         nonprob    not_recom   not_recom  \n",
       "7844   slightly_prob    not_recom   not_recom  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parents</th>\n      <th>has_nurs</th>\n      <th>form</th>\n      <th>children</th>\n      <th>housing</th>\n      <th>finance</th>\n      <th>social</th>\n      <th>health</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6142</th>\n      <td>pretentious</td>\n      <td>improper</td>\n      <td>complete</td>\n      <td>2</td>\n      <td>critical</td>\n      <td>convenient</td>\n      <td>slightly_prob</td>\n      <td>priority</td>\n      <td>spec_prior</td>\n    </tr>\n    <tr>\n      <th>4041</th>\n      <td>usual</td>\n      <td>very_crit</td>\n      <td>incomplete</td>\n      <td>3</td>\n      <td>critical</td>\n      <td>inconv</td>\n      <td>nonprob</td>\n      <td>recommended</td>\n      <td>spec_prior</td>\n    </tr>\n    <tr>\n      <th>12506</th>\n      <td>great_pret</td>\n      <td>very_crit</td>\n      <td>completed</td>\n      <td>more</td>\n      <td>less_conv</td>\n      <td>inconv</td>\n      <td>slightly_prob</td>\n      <td>not_recom</td>\n      <td>not_recom</td>\n    </tr>\n    <tr>\n      <th>8147</th>\n      <td>pretentious</td>\n      <td>very_crit</td>\n      <td>completed</td>\n      <td>3</td>\n      <td>critical</td>\n      <td>inconv</td>\n      <td>nonprob</td>\n      <td>not_recom</td>\n      <td>not_recom</td>\n    </tr>\n    <tr>\n      <th>7844</th>\n      <td>pretentious</td>\n      <td>very_crit</td>\n      <td>complete</td>\n      <td>2</td>\n      <td>convenient</td>\n      <td>inconv</td>\n      <td>slightly_prob</td>\n      <td>not_recom</td>\n      <td>not_recom</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# AVL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10430 entries, 0 to 10429\nData columns (total 11 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   0       10430 non-null  float64\n 1   1       10430 non-null  float64\n 2   2       10430 non-null  float64\n 3   3       10430 non-null  float64\n 4   4       10430 non-null  float64\n 5   5       10430 non-null  float64\n 6   6       10430 non-null  float64\n 7   7       10430 non-null  float64\n 8   8       10430 non-null  float64\n 9   9       10430 non-null  float64\n 10  target  10430 non-null  object \ndtypes: float64(10), object(1)\nmemory usage: 896.5+ KB\nNone\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.266074 -0.165620  0.320980  0.483299  0.172340  0.273364  0.371178   \n",
       "1  0.130292  0.870736 -3.210528  0.062493  0.261718  1.436060  1.465940   \n",
       "2 -0.116585  0.069915  0.068476 -0.783147  0.261718  0.439463 -0.081827   \n",
       "3  0.031541  0.297600 -3.210528 -0.583590 -0.721442 -0.307984  0.710932   \n",
       "4  0.229043  0.807926 -0.052442  0.082634  0.261718  0.148790  0.635431   \n",
       "\n",
       "          7         8         9 target  \n",
       "0  0.929823  0.251173  0.159345      A  \n",
       "1  0.636203  0.282354  0.515587      A  \n",
       "2 -0.888236 -0.123005  0.582939      A  \n",
       "3  1.051693  0.594169 -0.533994      A  \n",
       "4  0.051062  0.032902 -0.086652      F  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.266074</td>\n      <td>-0.165620</td>\n      <td>0.320980</td>\n      <td>0.483299</td>\n      <td>0.172340</td>\n      <td>0.273364</td>\n      <td>0.371178</td>\n      <td>0.929823</td>\n      <td>0.251173</td>\n      <td>0.159345</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.130292</td>\n      <td>0.870736</td>\n      <td>-3.210528</td>\n      <td>0.062493</td>\n      <td>0.261718</td>\n      <td>1.436060</td>\n      <td>1.465940</td>\n      <td>0.636203</td>\n      <td>0.282354</td>\n      <td>0.515587</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.116585</td>\n      <td>0.069915</td>\n      <td>0.068476</td>\n      <td>-0.783147</td>\n      <td>0.261718</td>\n      <td>0.439463</td>\n      <td>-0.081827</td>\n      <td>-0.888236</td>\n      <td>-0.123005</td>\n      <td>0.582939</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.031541</td>\n      <td>0.297600</td>\n      <td>-3.210528</td>\n      <td>-0.583590</td>\n      <td>-0.721442</td>\n      <td>-0.307984</td>\n      <td>0.710932</td>\n      <td>1.051693</td>\n      <td>0.594169</td>\n      <td>-0.533994</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.229043</td>\n      <td>0.807926</td>\n      <td>-0.052442</td>\n      <td>0.082634</td>\n      <td>0.261718</td>\n      <td>0.148790</td>\n      <td>0.635431</td>\n      <td>0.051062</td>\n      <td>0.032902</td>\n      <td>-0.086652</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "\n",
    "avl=pd.read_csv('../data/raw/avl_set/avila-tr.txt', header=None)\n",
    "avl.columns = avl.columns.astype(str)\n",
    "avl=avl.rename(columns={'10':'target'})\n",
    "avl_train = avl.sample(n=5000, replace=False)\n",
    "avl_test = cleaning_nsr.drop(avl_train.index)\n",
    "nsr_train.to_csv('../data/train/avl.csv', index=False)\n",
    "nsr_test .to_csv('../data/test/avl.csv', index=False)\n",
    "print(avl.info())\n",
    "avl.head()\n"
   ]
  },
  {
   "source": [
    "# POWER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AutoML directory: AutoML_1\n",
      "The task is multiclass_classification with evaluation metric logloss\n",
      "AutoML will use algorithms: ['Decision Tree', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'all_ints_encoding', 'loo_encoding', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree logloss 0.4222 trained in 1.29 seconds\n",
      "Adjust validation. Remove: AutoML_1/1_DecisionTree\n",
      "Validation strategy: 10-fold CV Shuffle,Stratify\n",
      "* Step simple_algorithms will try to check up to 2 models\n",
      "1_DecisionTree logloss 0.449552 trained in 13.4 seconds\n",
      "2_DecisionTree logloss 0.368499 trained in 8.96 seconds\n",
      "* Step default_algorithms will try to check up to 7 models\n",
      "2020-12-18 04:21:29,402 supervised.exceptions ERROR Stop training after the first fold. Time needed to train on the first fold 674.0 seconds. The time estimate for training on all folds is larger than total_time_limit.\n",
      "There was an error during 3_Default_Xgboost training.\n",
      "Please check AutoML_1/errors.md for details.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-9dca37318556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0mauto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Compete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/automl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mAutoML\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReturns\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/base_automl.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    898\u001b[0m                             )\n\u001b[1;32m    899\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                             \u001b[0mtrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"trained\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"skipped\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"final_loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_final_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/base_automl.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;34mf\"Train model #{len(self._models)+1} / Model name: {params['name']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         )\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;31m# save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/model_framework.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_iteration_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                     learner.fit(\n\u001b[0m\u001b[1;32m    152\u001b[0m                         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_to_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/supervised/algorithms/lightgbm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_validation, y_validation, log_to_file)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mesr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mevals_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             self.model = lgb.train(\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mlgb_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rna/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2368\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2371\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train/avl.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=['target']), df.target, test_size=0.25\n",
    "   \n",
    ")\n",
    "auto = AutoML(mode=\"Compete\")\n",
    "auto.fit(X_train,y_train)\n",
    "predictions = automl.predict_all(X_test)\n",
    "\n",
    "print(predictions.head())\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, predictions[\"label\"].astype(int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "prediction = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}